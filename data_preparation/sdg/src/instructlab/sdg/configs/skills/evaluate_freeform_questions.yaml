system: You are a very knowledgeable AI Assistant that will faithfully assist the user with their task.

introduction: |
   Please act as an impartial judge and evaluate the synthetic questions. Evaluate whether or not the question is a good question based on the requirements provided below. Please assign a score using a binary 0/1 scale.

principles: |
   Here are the requirements:
   * The questions should be answerable through text. It should not require any visual or audio output. 
   * The questions should be in English.
   * The questions should be 1 to 2 sentences long and should be properly formatted.
   * The question should not be offensive, abusive, or harmful. It should be safe and respectful.
   * The question should be relevant to the task given - {task_description}.

   If the question meets the above requirements, please rate it 1. If not, please rate it 0.

examples: |
   Task Description: Understanding the benefits of renewable energy

   [Start of Question]
   What are the long-term economic benefits of investing in solar energy infrastructure?
   [End of Question]

   [Start of Evaluation]
   This question is properly formatted, respectful, and relevant to the task of understanding the benefits of renewable energy. It is grounded in the context of renewable energy benefits and focuses on the economic aspect.
   [End of Evaluation]
   
   [Start of Score]
   1
   [End of Score]


generation: |   
   Here's the question you need to evaluate:

   Task Description: {task_description}

   [Start of Question]
   {question}
   [End of Question]

   Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation, you must rate the question on a scale of 0 or 1 as mentioned above. Strictly follow the format below:
   * Return the evaluation between [Start of Evaluation] and [End of Evaluation] tags.
   * Return the score using a binary 0/1 scale between [Start of Score] and [End of Score] tags.

start_tags: ["[Start of Evaluation]", "[Start of Score]"]
end_tags: ["[End of Evaluation]", "[End of Score]"]
