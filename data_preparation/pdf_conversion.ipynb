{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install instructlab==0.19.0\n",
    "!SETUPTOOLS_SCM_PRETEND_VERSION=0.1 pip install --ignore-installed --upgrade ./sdg\n",
    "!pip install docling-parse==1.3.0\n",
    "!pip install docling==1.16.1\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "from utils.data import postprocess_and_save, pretty_print_dict\n",
    "from instructlab.sdg.utils.docprocessor import DocProcessor"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setup Instructions\n",
    "\n",
    "This demo demonstrates the process of converting raw PDF files into InstructLab Synthetic Knowledge Infusion Data using the RBC POC as an example. Follow these steps to get started with your own data.\n",
    "\n",
    "#### Steps to Get Started:\n",
    "\n",
    "1. **Organize Your Documents:**\n",
    "   - Create a new directory under the `document_collection` directory for your specific project. For example, if your project is named \"my_org,\" your directory structure should look like this:\n",
    "     ```\n",
    "     |-- document_collection\n",
    "     |   `-- my_org\n",
    "     |       |-- my_org_data.pdf\n",
    "     |       `-- qna.yaml\n",
    "     ```\n",
    "   - Place all your PDF files and ICL files (like `qna.yaml`) into this directory.\n",
    "\n",
    "2. **Format Your ICLs:**\n",
    "   - Ensure your ICL files contain sufficient context and question-answer pairs. We recommend including at least 5 distinct contexts, each with a minimum of 3 sets of questions and answers. More entries will improve the robustness of your data.\n",
    "    - The ICL file should be in the following format (refer to the `document_collection/my_org/qna.yaml` file for an example):\n",
    "\n",
    "    ```yaml\n",
    "    domain: \n",
    "    document_outline: A one to two line description of the document\n",
    "    seed_examples:\n",
    "      - context: <context 1 goes here>\n",
    "        question_and_answers:\n",
    "          - question: <question 1 goes here>\n",
    "            answer: <answer 1 goes here>\n",
    "          - question: <question 2 goes here>\n",
    "            answer: <answer 2 goes here>\n",
    "          - question: <question 3 goes here>\n",
    "            answer: <answer 3 goes here>\n",
    "    ... \n",
    "\n",
    "\n",
    "   - **Note:** Replace placeholders with actual content relevant to your documents. Ensure the contexts are clear and questions are well-formulated to extract meaningful answers.\n",
    "\n",
    "3. **Update the Data Directory Path:**\n",
    "   - In the script or code where the data directory is specified, update the `data_dir` variable to reflect the path to your new directory. For example:\n",
    "     ```python\n",
    "     data_dir = \"document_collection/my_org\"\n",
    "     ```\n",
    "4. **Update the Output Directory Path:**\n",
    "   - In the script or code where the data directory is specified, update the `output_dir` variable to reflect the path to your directory. For example:\n",
    "     ```python\n",
    "     data_dir = \"output/my_org\"\n",
    "     ```\n",
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Access the variables\n",
    "data_dir = os.getenv('DATA_DIR')\n",
    "output_dir = os.getenv('OUTPUT_DIR')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Documents to Seed Dataset\n",
    "\n",
    "To convert PDF documents into a usable seed dataset, we employ [Docling](https://github.com/DS4SD/docling), a tool designed for extracting and processing text from PDF files. The text extraction process involves parsing the PDF documents and saving the extracted text into a structured JSON file. The extracted text in JSON format can be used to generate InstructLab Synthetic Knowledge Infusion Data.\n",
    "\n",
    "\n",
    "#### Step 1: \n",
    "\n",
    "Run the following command to extract text from the PDF documents and save it in JSON format:\n",
    "\n",
    "⚠️ **Note:** This process takes about 5 minutes to run for this example\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!echo $data_dir\n",
    "!python ./sdg/scripts/docparser.py --input-dir {data_dir} --output-dir {output_dir}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: \n",
    "\n",
    "Now that we have extracted the text from the PDF documents, we can proceed to process the extracted data, we do the following:\n",
    "\n",
    "- Split the extracted text into chunks \n",
    "- Populate user provided ICLs with the chunks "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dp = DocProcessor(output_dir, user_config_path=f'{data_dir}/qna.yaml')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "seed_data = dp.get_processed_dataset()\n",
    "seed_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "seed_data.to_json(f'{output_dir}/seed_data.jsonl', orient='records', lines=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pretty_print_dict(f'{output_dir}/seed_data.jsonl')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convert JSONL to markdown files"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "md_output_dir = f\"{output_dir}/md\"\n",
    "os.makedirs(md_output_dir, exist_ok=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_document(index, document_text):\n",
    "    file_name = f\"document_{index+1}.md\"\n",
    "    file_path = os.path.join(md_output_dir, file_name)\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(document_text)\n",
    "    \n",
    "    print(f\"Saved {file_path}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "jsonl_file_path = f\"{output_dir}/seed_data.jsonl\"",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(jsonl_file_path, 'r') as f:\n",
    "    saved_hashes = set()\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        entry = json.loads(line)\n",
    "        document_text = entry.get('document', '')\n",
    "        h = hash(document_text)\n",
    "        if h not in saved_hashes:\n",
    "            saved_hashes.add(h)\n",
    "            save_document(i, document_text)\n",
    "            i += 1"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbc_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
